{
  "results": {
    "arc_easy": {
      "acc": 0.46254208754208753,
      "acc_stderr": 0.010230952104570798,
      "acc_norm": 0.4351851851851852,
      "acc_norm_stderr": 0.010173216430370915
    },
    "hellaswag": {
      "acc": 0.3580959968133838,
      "acc_stderr": 0.004784607222774635,
      "acc_norm": 0.43706432981477794,
      "acc_norm_stderr": 0.00495009555596467
    },
    "boolq": {
      "acc": 0.6244648318042814,
      "acc_stderr": 0.008469774334938066
    },
    "arc_challenge": {
      "acc": 0.2568259385665529,
      "acc_stderr": 0.012766923794116801,
      "acc_norm": 0.3054607508532423,
      "acc_norm_stderr": 0.013460080478002498
    },
    "openbookqa": {
      "acc": 0.156,
      "acc_stderr": 0.016243636028391115,
      "acc_norm": 0.278,
      "acc_norm_stderr": 0.020055833888070914
    },
    "winogrande": {
      "acc": 0.5090765588003157,
      "acc_stderr": 0.014050170094497704
    },
    "piqa": {
      "acc": 0.5794341675734495,
      "acc_stderr": 0.01151766561128278,
      "acc_norm": 0.5761697497279652,
      "acc_norm_stderr": 0.01152966327027629
    }
  },
  "versions": {
    "arc_easy": 0,
    "hellaswag": 0,
    "boolq": 1,
    "arc_challenge": 0,
    "openbookqa": 0,
    "winogrande": 0,
    "piqa": 0
  },
  "config": {
    "model": "hf-causal-experimental",
    "model_args": "checkpoint=prune_log/Qwen2.5-Math-7B_s0.10/pytorch_model.bin,peft=tune_log/Qwen2.5-Math-7B_s0.10/checkpoint-1400,config_pretrained=Qwen/Qwen2.5-Math-7B",
    "num_fewshot": 0,
    "batch_size": null,
    "device": "cuda:0",
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}